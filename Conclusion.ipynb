{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bdd9d2f",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1fa4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbec272",
   "metadata": {},
   "source": [
    "    To make a long story short, during this challenged we asked first of all to predict the next 2 hours of rides in the city of Boston and in addition to address at least one new research question. \n",
    "    \n",
    "    \n",
    "    Regarding the first part, we took the chance to create a very basic model using only the time series of previous time intervals rides in order to predict the next two hours. By grouping in 15, 30, 60 and 120 minutes two hours ago since the point of time we wanted to predict, we managed to construct a Tree based ensemble model predicting the nect two hours rides with R_squared score almost 90%. The more narrow the time interval was the better the performance of our model, which is something really understandable since we had more accurate information for this period. We also introduced for the first seen we had not seen it in the classroom, a way of back testing validation.\n",
    "    \n",
    "    As far as the explorent component is concerned, we took the initiative to put on the table two different questions. How do the weather data affects the bike demand? Could we create a model to predict the demand per cluster of stations instead of the overall pickup only? We underline the only, since the demand per cluster sums up the total demand. Meaningful insights came out through these two questions, helping us to set up the final dataset for the prediction using the weather data and achive also a 90% score. The Tree based models proved that they were mainly affected by the lags when on the other hand the linear models were affected also significantly by the weather feautures. The most import weather features were the temprature, the humidity and also the snowdepth and uvindex. On the other hand, during clustering we managed to use techniques from the class beyond regression and data preparation only as we distributed the stations in 5 clusters, and visualized their distribution on the map. We ended up, testing a linear Multi Output Regression model and a tree based one, both of them we with acceptable performance is we take in consideration the few features we used and that we tested them in the 60 minutes interval only. Making use of the previous 2 hours pickups per cluster seems not to be enough to construct a robust model.\n",
    "    \n",
    "    Overall, excepts from knwledge the project has created also new questions about the way of using lags and feautures could affect the quality and performance of a machine kearning project. Also the use of parameters optimazation tools like GridSearch could be proved important in the effort and probably the change of some weather features. The data enrichment from other sources and more observations are also another way of success.\n",
    "    \n",
    "    At this point, we would like to mention that we really enjoyed the course and the way what we have learned so many useful techniques and machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22225c",
   "metadata": {},
   "source": [
    "### Contribution Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf80e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section                        CristobalDonoso/s222508    GeorgiosPanagiotopoulos/s223306    TadeoRamirez/s221877\n",
      "-----------------------------  -------------------------  ---------------------------------  ----------------------\n",
      "1:  Introduction               25.00%                     20.00%                             55.00%\n",
      "2:  Prediction Chalenge        14.00%                     68.00%                             18.00%\n",
      "3.1:Explorent Component Part1  14.00%                     66.00%                             20.00%\n",
      "3.2:Explorent Component Part2  13.00%                     68.00%                             19.00%\n",
      "4:  Conclusion                 13.00%                     67.00%                             20.00%\n"
     ]
    }
   ],
   "source": [
    "headers =     ['Section', 'CristobalDonoso/s222508', 'GeorgiosPanagiotopoulos/s223306', 'TadeoRamirez/s221877',]\n",
    "intro =       ['1:  Introduction',                '25.00%', '20.00%', '55.00%']\n",
    "prediction =  ['2:  Prediction Chalenge',         '14.00%', '68.00%', '18.00%']\n",
    "explorent1 =  ['3.1:Explorent Component Part1',   '14.00%', '66.00%', '20.00%']\n",
    "explorent2 =  ['3.2:Explorent Component Part2',   '13.00%', '68.00%', '19.00%']\n",
    "conclusion =  ['4:  Conclusion',                  '13.00%', '67.00%', '20.00%']\n",
    "data = [intro,prediction,explorent1,explorent2,conclusion]\n",
    "print(tabulate(data, headers=headers,colalign=(\"left\",), floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0466ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
